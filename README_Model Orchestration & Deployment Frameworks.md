# Model Orchestration Frameworks

* [Hopsworks](https://github.com/logicalclocks/hopsworks) ![](https://img.shields.io/github/stars/logicalclocks/hopsworks.svg?style=social) - Hopsworks is a data-intensive platform for the design and operation of machine learning pipelines that includes a Feature Store. [(Video)](https://www.youtube.com/watch?v=v1DrnY8caVU).

* [Kubeflow](https://github.com/kubeflow/kubeflow) ![](https://img.shields.io/github/stars/kubeflow/kubeflow.svg?style=social) - A cloud native platform for machine learning based on Google’s internal machine learning pipelines.

* [Open Platform for AI](https://github.com/Microsoft/pai) ![](https://img.shields.io/github/stars/Microsoft/pai.svg?style=social) - Platform that provides complete AI model training and resource management capabilities.

* [PyCaret](https://pycaret.org/) ![](https://img.shields.io/github/stars/pycaret/pycaret.svg?style=social)) - low-code library for training and deploying models (scikit-learn, XGBoost, LightGBM, spaCy)

* [Redis-AI](https://github.com/RedisAI/RedisAI) ![](https://img.shields.io/github/stars/RedisAI/RedisAI.svg?style=social) - A Redis module for serving tensors and executing deep learning models. Expect changes in the API and internals.


* [Skaffold](https://github.com/GoogleContainerTools/skaffold) ![]() - Skaffold is a command line tool that facilitates continuous development for Kubernetes applications. You can iterate on your application source code locally then deploy to local or remote Kubernetes clusters.


# Model Deployment Frameworks

 - [Tensorflow Serving](httpswww.tensorflow.orgserving) ![](httpsimg.shields.iogithubstarstensorflowserving.svgstyle=social) - High-performant framework to serve Tensorflow models via grpc protocol able to handle 100k requests per second per core

 - [Seldon](httpsgithub.comSeldonIOseldon-core) ![](httpsimg.shields.iogithubstarsSeldonIOseldon-core.svgstyle=social) - Open source platform for deploying and monitoring machine learning models in kubernetes - [(Video)](httpswww.youtube.comwatchv=pDlapGtecbY)


 - [KFServing](httpsgithub.comkubeflowkfserving) ![](httpsimg.shields.iogithubstarskubeflowkfserving.svgstyle=social) - Serverless framework to deploy and monitor machine learning models in Kubernetes - [(Video)](httpswww.youtube.comwatchv=hGIvlFADMhU)

 - [NVIDIA TensorRT Inference Server](httpsgithub.comNVIDIAtensorrt-inference-server) - TensorRT Inference Server is an inference microservice that lets you serve deep learning models in production while maximizing GPU utilization.
 - [NVIDIA TensorRT](httpsgithub.comNVIDIATensorRT) - TensorRT is a C++ library for high performance inference on NVIDIA GPUs and deep learning accelerators.


 - [DeepDetect](httpsgithub.combenizdeepdetect) ![](httpsimg.shields.iogithubstarsbenizdeepdetect.svgstyle=social) - Machine Learning production server for TensorFlow, XGBoost and Cafe models written in C++ and maintained by Jolibrain

 - [MLeap](httpsgithub.comcombustmleap) ![](httpsimg.shields.iogithubstarscombustmleap.svgstyle=social) - Standardisation of pipeline and model serialization for Spark, Tensorflow and sklearn




 - [BentoML](httpsgithub.combentomlBentoML) ![](httpsimg.shields.iogithubstarsbentomlbentoml.svgstyle=social) - BentoML is an open source framework for high performance ML model serving
 - [Clipper](httpsgithub.comucbriseclipper) ![](httpsimg.shields.iogithubstarsucbriseclipper.svgstyle=social) - Model server project from Berkeley's Rise Rise Lab which includes a standard RESTful API and supports TensorFlow, Scikit-learn and Caffe models

 - [Cortex](httpsgithub.comcortexlabscortex) ![]() - Cortex is an open source platform for deploying machine learning models—trained with nearly any framework—as production web services.

